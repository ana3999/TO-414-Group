---
title: "Project#3: Prediction"
author: "Group 1"
date: "3/29/2021"
output: html_document
---

```{r, include=FALSE}
# Required packages
library(tidyverse)
library(class)
library(caret)
library(gmodels)
library(neuralnet)
library(lmtest)
library(aod)
library(VGAM)
library(e1071)
library(C50)
```

#### Data Set-up

Reading and Cleaning data: 
```{r}
resume <- read.csv("ResumeNames.csv", stringsAsFactors = TRUE)
resume$name <- NULL
resume$X <- NULL
resume$minimum <- as.integer(resume$minimum)
str(resume)
```

## Introduction

This data set contains different features from 4,870 resumes. The response variable for this data set is whether a candidate was called back for an interview or not. 

An important issue to note before beginning our analysis is the imbalance within the data set. With the nature of the hiring process, most candidates will not be called back for an interview. Thus, the response variable is extremely imbalanced, with 4478 "no" outcomes, and only 392 "yes" outcomes. To compensate for this imbalance, the split for the testing and training data sets were lowered to a ratio of 30:70, rather than 20:80. Moreover, within the prediction models, cut-offs were also lowered to about 0.15-0.20, instead of exactly 0.5. 

### Creating Test and Train data sets (30:70 split)
```{r}
# Make all factors dummy variables
resumemm <- as.data.frame(model.matrix(~.-1, resume))
# Randomize the rows in the data (shuffling the rows)
set.seed(123)
res_random <- resumemm[sample(nrow(resumemm)),]
# Normalize the data
normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x)))}
resume_norm <- as.data.frame(lapply(res_random, normalize))
# resume_z <- as.data.frame(scale(res_random[-1]))

## Train and test sets for KNN
testrows <- sample(1:nrow(resume_norm), 0.3*nrow(resume_norm))
resume_train <- resume_norm[-testrows,-match("callyes",names(resume_norm))]
resume_test <- resume_norm[testrows, -match("callyes",names(resume_norm))]

## Train and test sets for other models
resume_train_2 <- resume_norm[-testrows,]
resume_test_2 <- resume_norm[testrows,]

#Now the response (aka Labels) - only the callyes column
res_train_labels <- resume_norm[-testrows, "callyes"]
res_test_labels <- resume_norm[testrows, "callyes"]

## Train and test sets without dummy variables and normalization
testrows_2 <- sample(1:nrow(resume), 0.3*nrow(resume))
resume_test_3 <- resume[testrows, ]
resume_train_3 <- resume[-testrows, ]
```

## Linear Regression

Using step function to remove insignificant variables
```{r, include=FALSE}
lin <- lm(callyes ~ ., data = resume_train_2, family = "binomial")
steplin <- step(lin)
```

### Model
```{r}
summary(steplin)
```

### Prediction
```{r}
linPred <- as.factor( ifelse(predict(lin, newdata = resume_test_2, type = "response") > 0.15, "1", "0") )
confusionMatrix(linPred, as.factor(resume_test_2$call), positive="1")
```

## Logistic Regression

Using step function to remove insignificant variables
```{r, include=FALSE}
lm1 <- glm(call ~ ., data = resume_train_3, family = "binomial")
steplm1 <- step(lm1)
```

### Model
```{r}
summary(steplm1)
```

### Prediction
```{r}
log2pred <- ifelse(predict(steplm1, newdata = resume_test_3, type = "response") > 0.2, 1, 0)
confusionMatrix(as.factor(log2pred), as.factor(res_test_labels))
```

## Decision Tree 

### Model
```{r}
namesModel <- C5.0(as.factor(callyes) ~ ., data = resume_train_2)
summary(namesModel)
plot(namesModel)
```

### Prediction
```{r}
CallPrediction <- predict(namesModel, resume_test_2)
CrossTable(res_test_labels, CallPrediction)
confusionMatrix(data = as.factor(CallPrediction), reference = as.factor(res_test_labels))
```

### Improved Model
```{r}
improvedNamesModel <- C5.0(as.factor(callyes) ~ ethnicitycauc + citychicago + jobs + experience + honorsyes + holesyes + emailyes + specialyes + collegeyes + equalyes + reqeducyes + reqcompyes + reqorgyes + industryfinance.insurance.real.estate + industryhealth.education.social.services + industrymanufacturing + industrytrade + industrytransport.communication + industryunknown , data = resume_test_2)
```

### Improved Model Prediction
```{r}
CallPrediction2 <- predict(improvedNamesModel, resume_test_2)
confusionMatrix(data = as.factor(CallPrediction2), reference = as.factor(res_test_labels))
```

## KNN

### Model
```{r}
knum <- sqrt(nrow(resume_train))
knn_pred <- knn(train = resume_train, test = resume_test, cl = res_train_labels, k=knum)
#summary(resume_train)
```

### Prediction
```{r}
caret::confusionMatrix(data = as.factor(knn_pred), reference = as.factor(res_test_labels))
```

## ANN 

### Model 1
```{r}
ANN_model1 <- neuralnet(callyes ~ . , data = resume_train_2, hidden = 1)
```

### Model 1 Prediction
```{r}
ANN_modelresults <- compute(ANN_model1, resume_test_2)
ANN_pred <- ANN_modelresults$net.result
resume_test_2$ANN_preds <- as.numeric(ifelse(ANN_pred > 0.20, 1, 0))
confusionMatrix(data = as.factor(resume_test_2$ANN_preds), reference = as.factor(resume_test_2$callyes), positive = '1')
```

### Model 2
```{r}
ANN_model2 <- neuralnet(callyes ~ ethnicitycauc + citychicago + jobs + experience + honorsyes + holesyes + emailyes + specialyes + collegeyes + equalyes + reqeducyes + reqcompyes + reqorgyes + industryfinance.insurance.real.estate + industryhealth.education.social.services + industrymanufacturing + industrytrade + industrytransport.communication + industryunknown , data = resume_train_2, hidden = 1)
```

### Model 2 Prediction
```{r}
ANN_model2results <- compute(ANN_model2, resume_test_2)
ANN_pred2 <- ANN_model2results$net.result
resume_test_2$ANN_preds <- as.numeric(ifelse(ANN_pred2 > 0.20, 1, 0))
confusionMatrix(data = as.factor(resume_test_2$ANN_preds), reference = as.factor(resume_test_2$callyes), positive = '1')
```

## Data Frame with Predictions
```{r}
comb_pred <- data.frame(knn2 = knn_pred, log2 = log2pred, ann2 = ANN_pred2, dec_tree = CallPrediction2, callyes = res_test_labels)
test_rows_3 <- sample(1:nrow(comb_pred),0.3*nrow(comb_pred))
resume_test_4 <- comb_pred[test_rows_3,]
resume_train_4 <- comb_pred[-test_rows_3,]
comb_train_labels <- comb_pred[-test_rows_3, "callyes"]
comb_test_labels <- comb_pred[test_rows_3, "callyes"]
tree_model_2 <- C5.0(as.factor(callyes) ~ knn2 + log2 + ann2 + dec_tree, data = resume_train_4)
tree_pred_2 <- predict(tree_model_2, resume_test_4)
caret::confusionMatrix(data = as.factor(tree_pred_2), reference = as.factor(comb_test_labels))
```

## Conclusion

* List confusionmatrix summaries
* Identify most accurate model
* Identify and explain which variables were most significant
